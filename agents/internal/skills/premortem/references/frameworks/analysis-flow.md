# Analysis Flow - è³ªå•ç”Ÿæˆã¨é¸æŠã®è©³ç´°ãƒ•ãƒ­ãƒ¼

## Overview

Premortemã‚¹ã‚­ãƒ«ã®è³ªå•ç”Ÿæˆã‹ã‚‰é¸æŠã€æç¤ºã¾ã§ã®è©³ç´°ãƒ•ãƒ­ãƒ¼ã€‚

## Phase 1: Context Gatheringï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†ï¼‰

### 1.1 ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®è§£æ

```python
# å…¥åŠ›ä¾‹
user_input = "Next.js + PostgreSQLã§ãƒ–ãƒ­ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹è¨ˆç”»"

# æŠ½å‡ºã™ã‚‹æƒ…å ±
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜: ä¸Šè¨˜ã®æ–‡å­—åˆ—å…¨ä½“
- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: "Next.js", "PostgreSQL"
- ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ’ãƒ³ãƒˆ: "ãƒ–ãƒ­ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ " â†’ Webé–‹ç™º
- æˆç†Ÿåº¦ãƒ’ãƒ³ãƒˆ: "è¨ˆç”»" â†’ POC ã¾ãŸã¯ MVP
```

### 1.2 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•æ¤œå‡º

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä»¥ä¸‹ã‚’æ¤œå‡ºï¼š

```
.kiro/steering/*.md         # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ–¹é‡
package.json                # Node.jsä¾å­˜é–¢ä¿‚
requirements.txt            # Pythonä¾å­˜é–¢ä¿‚
Cargo.toml                  # Rustä¾å­˜é–¢ä¿‚
README.md                   # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
docs/*.md                   # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
```

### æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯

```python
def auto_detect_files() -> List[Path]:
    files = []
    search_patterns = [
        ".kiro/steering/*.md",
        "package.json",
        "requirements.txt",
        "Cargo.toml",
        "README.md",
        "docs/*.md"
    ]
    for pattern in search_patterns:
        files.extend(glob(pattern))
    return files
```

### 1.3 ProjectContextç”Ÿæˆ

```python
context = ProjectContext(
    domain="web-development",      # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¤å®šçµæœ
    maturity="mvp",                # æˆç†Ÿåº¦æ¨å®š
    tech_stack=["Next.js", "PostgreSQL"],  # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æŠ½å‡º
    scale="medium",                # ã‚¹ã‚±ãƒ¼ãƒ«åˆ¤å®š
    description=user_input         # å…ƒã®èª¬æ˜
)
```

## Phase 2: Question Generationï¼ˆè³ªå•ç”Ÿæˆï¼‰

### 2.1 è³ªå•ãƒ—ãƒ¼ãƒ«ã®ãƒ­ãƒ¼ãƒ‰

```python
# æ±ç”¨è³ªå•ï¼ˆå…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…±é€šï¼‰
generic_questions = load_yaml("references/questions/generic.yaml")  # 35å•

# ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥è³ªå•ï¼ˆweb-developmentï¼‰
domain_questions = load_yaml("references/questions/web-development.yaml")  # 20å•

# åˆè¨ˆ: 55å•ã®è³ªå•ãƒ—ãƒ¼ãƒ«
all_questions = generic_questions + domain_questions
```

### 2.2 é–¢é€£åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

å„è³ªå•ã«å¯¾ã—ã¦é–¢é€£åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰ã‚’è¨ˆç®—ï¼š

```python
def score_question(question: Dict, context: ProjectContext) -> float:
    score = 0.0

    # 1. ãƒˆãƒªã‚¬ãƒ¼ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒï¼ˆæœ€å¤§ +0.3ï¼‰
    triggers = question.get("triggers", [])
    if any(trigger in context.description.lower() for trigger in triggers):
        score += 0.3

    # 2. ãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆï¼ˆ+0.2ï¼‰
    relevance_boost = question.get("relevance_boost", {})
    if context.domain in relevance_boost.get("domains", []):
        score += 0.2

    # 3. æˆç†Ÿåº¦é©åˆï¼ˆ+0.2ï¼‰
    if context.maturity in relevance_boost.get("maturity", []):
        score += 0.2

    # 4. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ãƒãƒƒãƒï¼ˆæœ€å¤§ +0.3ï¼‰
    question_text = question.get("text", "").lower()
    if any(tech.lower() in question_text for tech in context.tech_stack):
        score += 0.3

    return min(score, 1.0)
```

### ã‚¹ã‚³ã‚¢ä¾‹

| è³ªå•ID  | ãƒˆãƒªã‚¬ãƒ¼ | ãƒ‰ãƒ¡ã‚¤ãƒ³ | æˆç†Ÿåº¦ | æŠ€è¡“ | åˆè¨ˆã‚¹ã‚³ã‚¢ |
| ------- | -------- | -------- | ------ | ---- | ---------- |
| WEB-001 | 0.3      | 0.2      | 0.2    | 0.0  | 0.7        |
| GEN-011 | 0.3      | 0.2      | 0.2    | 0.0  | 0.7        |
| WEB-012 | 0.0      | 0.2      | 0.2    | 0.3  | 0.7        |
| GEN-016 | 0.0      | 0.2      | 0.0    | 0.0  | 0.2        |

### 2.3 è³ªå•ã®é¸æŠ

ã‚¹ã‚³ã‚¢ã¨å„ªå…ˆåº¦ã«åŸºã¥ã„ã¦3-5å•ã‚’é¸æŠï¼š

```python
def select_top_questions(
    questions: List[Dict],
    context: ProjectContext,
    min_count: int = 3,
    max_count: int = 5,
    min_score: float = 0.5
) -> List[Dict]:
    # 1. ã‚¹ã‚³ã‚¢è¨ˆç®—
    scored = [(q, score_question(q, context)) for q in questions]

    # 2. ã‚½ãƒ¼ãƒˆï¼ˆã‚¹ã‚³ã‚¢é™é †ã€æ¬¡ã«å„ªå…ˆåº¦ï¼‰
    priority_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
    sorted_q = sorted(
        scored,
        key=lambda x: (-x[1], priority_order.get(x[0].get("priority"), 2))
    )

    # 3. ã‚¹ã‚³ã‚¢é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿
    filtered = [q for q, s in sorted_q if s >= min_score]

    # 4. ãƒˆãƒƒãƒ—Nå•ã‚’é¸æŠ
    if len(filtered) >= min_count:
        return filtered[:max_count]
    else:
        # ä¸è¶³ã™ã‚‹å ´åˆã¯ä½ã‚¹ã‚³ã‚¢ã‚‚å«ã‚ã‚‹
        return sorted_q[:min_count]
```

### é¸æŠä¾‹

```
é¸æŠã•ã‚ŒãŸè³ªå•ï¼ˆ5å•ï¼‰:
1. WEB-001 (score: 0.92) - RESTfulè¨­è¨ˆåŸå‰‡
2. GEN-011 (score: 0.88) - èªè¨¼ãƒ»èªå¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
3. WEB-012 (score: 0.85) - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ
4. GEN-019 (score: 0.82) - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¨ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°
5. WEB-006 (score: 0.78) - OWASP Top 10å¯¾ç­–
```

### 2.4 ã‚«ãƒ†ã‚´ãƒªãƒãƒ©ãƒ³ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

åŒã˜ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰åã£ã¦é¸æŠã•ã‚Œã‚‹ã®ã‚’é˜²ãï¼š

```python
def balance_categories(questions: List[Dict], max_per_category: int = 2) -> List[Dict]:
    category_counts = {}
    balanced = []

    for q in questions:
        category = q.get("category", "other")
        if category_counts.get(category, 0) < max_per_category:
            balanced.append(q)
            category_counts[category] = category_counts.get(category, 0) + 1

    return balanced
```

## Phase 3: Interactive Reviewï¼ˆå¯¾è©±çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰

### 3.1 è³ªå•ã®æç¤º

å„è³ªå•ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§1ã¤ãšã¤æç¤ºï¼š

```markdown
## Q1: RESTfulè¨­è¨ˆåŸå‰‡ï¼ˆPriority: Criticalï¼‰

ã“ã®APIã¯RESTfulè¨­è¨ˆåŸå‰‡ã‚’éµå®ˆã—ã¦ã„ã¾ã™ã‹ï¼Ÿ

- ãƒªã‚½ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®URLè¨­è¨ˆï¼ˆ/users/{id}ã€/orders/{id}ï¼‰ã«ãªã£ã¦ã„ã¾ã™ã‹ï¼Ÿ
- HTTPãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆGETã€POSTã€PUTã€DELETEã€PATCHï¼‰ã®ä½¿ã„åˆ†ã‘ã¯é©åˆ‡ã§ã™ã‹ï¼Ÿ
- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ï¼ˆ200ã€201ã€400ã€401ã€404ã€500ç­‰ï¼‰ã®ä½¿ç”¨ã¯æ­£ã—ã„ã§ã™ã‹ï¼Ÿ
- HATEOASï¼ˆHypermedia as the Engine of Application Stateï¼‰ã¯æ¤œè¨ã—ã¾ã—ãŸã‹ï¼Ÿ

**ãªãœé‡è¦ã‹**: RESTfulè¨­è¨ˆã«å¾“ã‚ãªã„APIã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚Šã€ä¿å®ˆæ€§ãŒä½ä¸‹ã—ã¾ã™ã€‚
```

### 3.2 å›ç­”ã®åˆ†æ

ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”ã‚’è§£æã—ã€ä¸è¶³æ¦‚å¿µã‚’æ¤œå‡ºï¼š

```python
def analyze_response(question: Dict, response: str) -> Dict:
    analysis = {
        "is_sufficient": True,
        "missing_concepts": [],
        "follow_up_needed": False
    }

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    question_keywords = extract_keywords(question["text"])
    for keyword in question_keywords:
        if keyword not in response.lower():
            analysis["missing_concepts"].append(keyword)
            analysis["is_sufficient"] = False

    # ã€Œã‚ã‹ã‚‰ãªã„ã€ã€Œä¸æ˜ã€ç­‰ã®ãƒ•ãƒ©ã‚°ãƒã‚§ãƒƒã‚¯
    uncertain_phrases = ["ã‚ã‹ã‚‰ãªã„", "ä¸æ˜", "æœªå®š", "æ¤œè¨ä¸­"]
    if any(phrase in response.lower() for phrase in uncertain_phrases):
        analysis["is_sufficient"] = False
        analysis["follow_up_needed"] = True

    return analysis
```

### 3.3 æ·±å €ã‚Šè³ªå•ï¼ˆæœ€å¤§2å›ï¼‰

ä¸è¶³æ¦‚å¿µãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€æ·±å €ã‚Šè³ªå•ã‚’ç”Ÿæˆï¼š

```python
def generate_follow_up(missing_concepts: List[str], max_depth: int = 2) -> str:
    if not missing_concepts or max_depth == 0:
        return None

    # ä¾‹: "HATEOAS" ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
    if "hateoas" in [c.lower() for c in missing_concepts]:
        return """
HATEOASï¼ˆHypermedia as the Engine of Application Stateï¼‰ã«ã¤ã„ã¦è£œè¶³ã—ã¾ã™ã€‚

ã“ã‚Œã¯RESTã®åˆ¶ç´„ã®1ã¤ã§ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã€Œæ¬¡ã«å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã®ãƒªãƒ³ã‚¯ã‚’å«ã‚ã‚‹ã“ã¨ã§ã™ã€‚

ä¾‹:
{
  "id": 123,
  "name": "John",
  "_links": {
    "self": "/users/123",
    "orders": "/users/123/orders",
    "delete": "/users/123"
  }
}

ã“ã®æ¦‚å¿µã¯ä»Šå›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å¿…è¦ã§ã™ã‹ï¼Ÿ
"""
    return None
```

### 3.4 æ¬¡ã®è³ªå•ã¸é·ç§»

å…¨è³ªå•ï¼ˆ5å•ï¼‰ã‚’é †ç•ªã«å‡¦ç†ï¼š

```python
for i, question in enumerate(selected_questions, 1):
    print(f"## Q{i}: {question['text'][:50]}...")
    response = input("å›ç­”: ")

    # å›ç­”åˆ†æ
    analysis = analyze_response(question, response)

    # æ·±å €ã‚Šï¼ˆæœ€å¤§2å›ï¼‰
    depth = 0
    while analysis["follow_up_needed"] and depth < 2:
        follow_up = generate_follow_up(analysis["missing_concepts"], max_depth=2-depth)
        if not follow_up:
            break
        print(follow_up)
        response = input("è¿½åŠ å›ç­”: ")
        analysis = analyze_response(question, response)
        depth += 1

    # æ¬¡ã®è³ªå•ã¸
    print("\n" + "="*60 + "\n")
```

## Phase 4: Report Generationï¼ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼‰

### 4.1 ç›²ç‚¹ã®åˆ†é¡

å…¨ã¦ã®å›ç­”ã‚’åˆ†æã—ã€ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¥ã«åˆ†é¡ï¼š

```python
def categorize_findings(questions_and_responses: List[Dict]) -> Dict:
    findings = {
        "critical": [],
        "medium": [],
        "low": [],
        "covered": []
    }

    for item in questions_and_responses:
        question = item["question"]
        response = item["response"]

        # å›ç­”ãŒä¸ååˆ†ãªå ´åˆ
        if is_insufficient(response):
            risk_level = map_priority_to_risk(question["priority"])
            findings[risk_level].append({
                "question_id": question["id"],
                "title": extract_title(question["text"]),
                "description": question["text"],
                "recommendation": generate_recommendation(question)
            })
        else:
            findings["covered"].append({
                "question_id": question["id"],
                "title": extract_title(question["text"])
            })

    return findings
```

### 4.2 ãƒ¬ãƒãƒ¼ãƒˆæ•´å½¢

ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼š

```markdown
# Premortem Analysis Report

**Generated**: 2026-02-13 14:30:22

## Project Context

- **Domain**: web-development
- **Maturity**: mvp
- **Scale**: medium
- **Tech Stack**: Next.js, PostgreSQL

## Critical Issues (ğŸ”´)

### 1. èªè¨¼ãƒ»èªå¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æœªå®šç¾©

OAuth2.0ã€JWTã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®é¸æŠãŒæ˜ç¢ºã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

**æ¨å¥¨å¯¾å¿œ**: Auth0ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶ã«å¿œã˜ãŸèªè¨¼æ–¹å¼ã‚’é¸å®šã—ã¦ãã ã•ã„ã€‚

## Medium Issues (ğŸŸ¡)

### 2. APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®æœªè€ƒæ…®

DoSå¯¾ç­–ãŒè¨ˆç”»ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚

**æ¨å¥¨å¯¾å¿œ**: Redis + Sliding Windowã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å°å…¥ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

## Already Covered (âœ…)

- RESTfulè¨­è¨ˆåŸå‰‡
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ

## Recommended Actions

1. **èªè¨¼æ–¹å¼ã®é¸å®š** (critical priority)

   - OAuth2.0ã€JWTã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒæ¤œè¨
   - Resources: https://auth0.com/docs

2. **APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…** (medium priority)
   - Redis + Sliding Windowã®è¨­è¨ˆ
   - Resources: https://redis.io/docs/manual/patterns/rate-limiter/

## Next Steps

1. å„ªå…ˆåº¦ã®é«˜ã„Critical/Medium Issuesã‹ã‚‰å¯¾å¿œã‚’é–‹å§‹ã—ã¦ãã ã•ã„
2. è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ç™ºè¦‹ã•ã‚ŒãŸç›²ç‚¹ã‚’åæ˜ ã—ã¦ãã ã•ã„
3. å®Ÿè£…é–‹å§‹å‰ã«å†åº¦ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„
```

### 4.3 ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```python
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’YAMLã§ä¿å­˜
session_data = {
    "timestamp": datetime.now().isoformat(),
    "context": asdict(context),
    "questions_and_responses": questions_and_responses,
    "findings": findings
}

output_path = Path(f".premortem-sessions/{datetime.now().strftime('%Y-%m-%d-%H%M%S')}.yaml")
output_path.parent.mkdir(exist_ok=True)

with open(output_path, "w") as f:
    yaml.dump(session_data, f, allow_unicode=True)
```

## Performance Optimization

### ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

åŒã˜ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§è¤‡æ•°å›å®Ÿè¡Œã™ã‚‹å ´åˆã€ã‚¹ã‚³ã‚¢ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼š

```python
@lru_cache(maxsize=100)
def score_question_cached(question_id: str, context_hash: str) -> float:
    # question_id ã¨ context_hash ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    pass
```

### ä¸¦åˆ—å‡¦ç†

è³ªå•ãƒ—ãƒ¼ãƒ«å…¨ä½“ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ä¸¦åˆ—åŒ–ï¼š

```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=4) as executor:
    scores = list(executor.map(
        lambda q: score_question(q, context),
        all_questions
    ))
```

## Error Handling

```python
try:
    context = analyze_context(user_input, files)
except Exception as e:
    print(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
    context = ProjectContext(
        domain="web-development",
        maturity="mvp",
        tech_stack=[],
        scale="medium",
        description=user_input
    )
```
